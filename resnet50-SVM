{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder,StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nfrom tensorflow.keras.models import Sequential, Model, load_model,save_model\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input, ZeroPadding2D, BatchNormalization, Activation, Add, AveragePooling2D, GlobalAveragePooling2D\nimport numpy as np\nfrom tensorflow.keras import activations\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.optimizers import Adam\nimport tensorflow as tf\nfrom sklearn.ensemble import RandomForestClassifier\nfrom keras.applications import vgg19, EfficientNetB0, ResNet50\nfrom PIL import Image\nimport cv2\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.pipeline import make_pipeline\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\nfrom tensorflow.keras.utils import to_categorical\nimport keras\nfrom sklearn.svm import SVC\nimport matplotlib.image as mpimg\nfrom glob import glob\nfrom keras.initializers import glorot_uniform\nfrom sklearn.model_selection import GridSearchCV\nimport xgboost as xgb\nimport joblib","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img_part_1 = ('/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1')\n\nimg_part_2 = ('/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2')\nos.makedirs('/kaggle/working/final_dataset')\nfinal_dataset = ('/kaggle/working/final_dataset')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def copy_images(source_path, destination_path):\n        for filename in os.listdir(source_path):\n            if filename.endswith('.jpg') or filename.endswith('.png'):\n                shutil.copy(os.path.join(source_path, filename), destination_path)\n\n\ncopy_images(img_part_1, final_dataset)\ncopy_images(img_part_2, final_dataset)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"meta_data = pd.read_csv('/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv')\n\nmeta_data.head()\nmeta_data['dx'].value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.makedirs('/kaggle/working/images')\n\nmeta_data['dx'].value_counts().plot(kind='bar')\nplt.title('Class Distribution')\nplt.xlabel('Lesion Type')\nplt.ylabel('Count')\nplt.show()\nplt.savefig('/kaggle/working/images/distribution.png')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"meta_data['Image_path'] = meta_data['image_id'].apply(lambda x: os.path.join(final_dataset, f\"{x}.jpg\"))\n\n\nle = LabelEncoder()\nmeta_data['label'] = le.fit_transform(meta_data[\"dx\"])\nmeta_data['label'] = meta_data['label'].astype(str)\n\n\nmeta_data.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"n_samples = 6705\n# Separating each class\ndf_nv = meta_data[meta_data['dx'] == 'nv']\ndf_mel = meta_data[meta_data['dx'] == 'mel']\ndf_bkl = meta_data[meta_data['dx'] == 'bkl']\ndf_bcc = meta_data[meta_data['dx'] == 'bcc']\ndf_akiec = meta_data[meta_data['dx'] == 'akiec']\ndf_vasc = meta_data[meta_data['dx'] == 'vasc']\ndf_df = meta_data[meta_data['dx'] == 'df']\n\n\ndf_nv_balanced = resample(df_nv, replace=False, n_samples=n_samples, random_state=42)\ndf_mel_balanced = resample(df_mel, replace=True, n_samples=n_samples, random_state=42)\ndf_bkl_balanced = resample(df_bkl, replace=True, n_samples=n_samples, random_state=42)\ndf_bcc_balanced = resample(df_bcc, replace=True, n_samples=n_samples, random_state=42)\ndf_akiec_balanced = resample(df_akiec, replace=True, n_samples=n_samples, random_state=42)\ndf_vasc_balanced = resample(df_vasc, replace=True, n_samples=n_samples, random_state=42)\ndf_df_balanced = resample(df_df, replace=True, n_samples=n_samples, random_state=42)\n\n\nbalanced_meta_data = pd.concat([df_nv_balanced, df_mel_balanced, df_bkl_balanced,\n                                    df_bcc_balanced, df_akiec_balanced, df_vasc_balanced,\n                                    df_df_balanced])\n\nlabel_mapping = {\n    'nv': 'Melanocytic Nevus',\n    'mel': 'Melanoma',\n    'bkl': 'Benign Keratosis',\n    'bcc': 'Basal Cell Carcinoma',\n    'akiec': 'Actinic Keratosis',\n    'vasc': 'Vascular Lesion',\n    'df': 'Dermatofibroma'\n}\n\nbalanced_meta_data['dx'] = balanced_meta_data['dx'].replace(label_mapping)\n\nprint(balanced_meta_data['dx'].value_counts())\nbalanced_meta_data = balanced_meta_data.sample(frac=1, random_state=42).reset_index(drop=True)\nprint(f\"Balanced dataset class distribution:\\n{balanced_meta_data['dx'].value_counts()}\")\n\n\nbalanced_meta_data.head()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_meta, test_meta = train_test_split(balanced_meta_data, test_size=0.3, random_state=42)\n    train_meta, val_meta = train_test_split(train_meta, test_size=0.3, random_state=42)\n\n    print(f\"Training set size: {len(train_meta)}\")\n    print(f\"Validation set size: {len(val_meta)}\")\n    print(f\"Testing set size: {len(test_meta)}\")\n\n    # Data augmentation and preprocessing\n    train_datagen = ImageDataGenerator(\n        rescale=1./255,\n        rotation_range=20,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest'\n    )\n\n    test_datagen = ImageDataGenerator(rescale=1./255)\n    # Train generator\n    train_generator = train_datagen.flow_from_dataframe(\n        dataframe=train_meta,\n        directory=final_dataset,\n        x_col='Image_path',\n        y_col='label',\n        target_size=(224, 224),\n        batch_size=64,\n        class_mode='categorical'\n    )\n\n    # Validation generator\n    val_generator = test_datagen.flow_from_dataframe(\n        dataframe=val_meta,\n        directory=final_dataset,\n        x_col='Image_path',\n        y_col='label',\n        target_size=(224, 224),\n        batch_size=64,\n        class_mode='categorical',\n        shuffle=False\n    )\n\n    # Test generator\n    test_generator = test_datagen.flow_from_dataframe(\n        dataframe=test_meta,\n        directory=final_dataset,\n        x_col='Image_path',\n        y_col='label',\n        target_size=(224, 224),\n        batch_size=64,\n        class_mode='categorical',\n        shuffle=False\n    )\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def identity_block(x,f,filters):\n    f1, f2, f3 = filters\n    x_shortcut = x\n\n    #Layer 1\n    x = Conv2D(filters= f1, kernel_size = (1,1),strides = (1,1), padding = 'valid')(x)\n    x = BatchNormalization(axis = 3)(x)\n    x = Activation('relu')(x)\n\n    #Layer 2\n    x = Conv2D(filters = f2, kernel_size = (f,f), strides =(1,1), padding='same')(x)\n    x = BatchNormalization(axis = 3)(x)\n    x = Activation('relu')(x)\n\n    #Layer 3\n    x = Conv2D(filters = f3, kernel_size = (1,1),strides = (1,1), padding = 'valid')(x)\n    x = BatchNormalization(axis = 3)(x)\n\n    #Adding the shortcut value\n    x = Add()([x,x_shortcut])\n    x = Activation('relu')(x)\n\n\n    return x\n\n\n\ndef convolutional_block(x,f,filters, s=2):\n\n    f1,f2,f3 = filters\n\n    x_shortcut = x\n\n    #Layer 1\n    x = Conv2D(filters = f1,kernel_size = (1,1), strides = (s,s))(x)\n    x = BatchNormalization(axis = 3)(x)\n    x = Activation('relu')(x)\n\n\n    #Layer 2\n    x = Conv2D(filters = f2, kernel_size = (f,f), strides = (1,1),padding = 'same')(x)\n    x = BatchNormalization(axis = 3)(x)\n    x = Activation('relu')(x)\n\n\n    #Layer 3\n    x = Conv2D(filters = f3, kernel_size = (1,1), strides = (1,1), padding = 'valid')(x)\n    x = BatchNormalization(axis = 3)(x)\n\n    # Shortcut\n    x_shortcut = Conv2D(filters = f3, kernel_size = (1,1), strides = (s,s), padding = 'valid')(x_shortcut)\n    x_shortcut = BatchNormalization(axis = 3)(x_shortcut)\n\n    x = Add()([x,x_shortcut])\n    x = Activation('relu')(x)\n\n    return x\n\n\n\n\ndef resnet50(input_shape = (224,224,3), classes = 7):\n\n    x_input = Input(input_shape)\n\n    x = ZeroPadding2D((3,3))(x_input)\n\n    #Stage 1\n    x = Conv2D(64,(7,7),strides = (2,2))(x)\n    x = BatchNormalization(axis = 3)(x)\n    x = Activation('relu')(x)\n    x = ZeroPadding2D((1,1))(x)\n    x = MaxPooling2D((3,3), strides = (2,2))(x)\n    \n\n\n    # Stage 2\n    x = convolutional_block(x,f=3, filters=[64,64,256], s=1)\n    x = identity_block(x,3,[64,64,256])\n    x = identity_block(x,3,[64,64,256])\n\n\n    #stage 3\n    x = convolutional_block(x,f=3, filters=[128,128,512], s=2)\n    x = identity_block(x,3,[128,128,512])\n    x = identity_block(x,3,[128,128,512])\n    x = identity_block(x,3,[128,128,512])\n\n    #Stage 4\n    x = convolutional_block(x,f=3, filters=[256,256,1024], s=2)\n    x = identity_block(x,3,[256,256,1024])\n    x = identity_block(x,3,[256,256,1024])\n    x = identity_block(x,3,[256,256,1024])\n    x = identity_block(x,3,[256,256,1024])\n    x = identity_block(x,3,[256,256,1024])\n\n\n    #Stage 5\n    x = convolutional_block(x,f=3, filters=[512,512,2048], s=2)\n    x = identity_block(x,3,[512,512,2048])\n    x = identity_block(x,3,[512,512,2048])\n\n    #avg pool\n    x = AveragePooling2D((2,2), name = 'avg_pool')(x)\n    x = Flatten()(x)\n    x = Dense(classes, activation = 'softmax', name = 'fc'+ str(classes), kernel_initializer = glorot_uniform(seed=0))(x)\n    model = Model(inputs = x_input, outputs = x, name= 'ResNet50')\n\n    return model\n\n\nresnet50_model = resnet50(input_shape=(224,224,3), classes = 7)\nresnet50_model.compile(optimizer='adam', loss= 'categorical_crossentropy', metrics = ['accuracy'])\nresnet50_model.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_accuracy',patience=10,restore_best_weights=True)\n\n\nhistory = resnet50_model.fit(\n    train_generator,\n    epochs=50,\n    validation_data=val_generator,\n    callbacks=[early_stopping]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loss, train_accuracy = resnet50_model.evaluate(train_generator)\nprint(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n\ntest_loss, test_accuracy = resnet50_model.evaluate(test_generator)\nprint(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.makedirs('/kaggle/working/saved_models')\n\nsave_model(resnet50_model, \"/kaggle/working/saved_models/resnet50_final.h5\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_generator.reset()\npredictions = resnet50_model.predict(test_generator, verbose=1)\ny_pred = np.argmax(predictions, axis=1)\ny_true = test_generator.classes\n\n\nclass_labels = {\n    0: 'Actinic Keratosis',    # akiec\n    1: 'Basal Cell Carcinoma', # bcc\n    2: 'Benign Keratosis',     # bkl\n    3: 'Dermatofibroma',       # df\n    4: 'Melanoma',            # mel\n    5: 'Melanocytic Nevi',    # nv\n    6: 'Vascular Lesion'      # vasc\n}\n\n\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(10, 7))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels.values(), yticklabels=class_labels.values())\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix')\nplt.show()\n# plt.save('/kaggle/working/images')\n\n\nprint(\"\\nClassification Report:\\n\")\nprint(classification_report(y_true, y_pred, target_names=class_labels.values()))\n\n\naccuracy = accuracy_score(y_true, y_pred)\nprecision = precision_score(y_true, y_pred, average='weighted')\nrecall = recall_score(y_true, y_pred, average='weighted')\nf1 = f1_score(y_true, y_pred, average='weighted')\n\n\nprint(f\"Overall Accuracy: {accuracy:.4f}\")\nprint(f\"Precision (Weighted): {precision:.4f}\")\nprint(f\"Recall (Weighted): {recall:.4f}\")\nprint(f\"F1-Score (Weighted): {f1:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n#  Combine ResNet50 with SVM, RF, KNN and XGBoost","metadata":{}},{"cell_type":"code","source":"#extract the features from the ResNet50 model excluding the fully connected or the dense layer\n\nlayer_name = 'avg_pool'\nintermediate_layer_model = Model(inputs=resnet50_model.input,outputs=resnet50_model.get_layer(layer_name).output)\n\n\ndef extract_features(generator, model, num_samples):\n    features = np.zeros((num_samples, model.output_shape[1]))  \n    labels = np.zeros((num_samples,))  \n    \n    i = 0\n    for inputs_batch, labels_batch in generator:\n        features_batch = intermediate_layer_model.predict(inputs_batch)\n        \n        # Check the shape of the features batch\n        print(f\"Batch {i}: features_batch shape: {features_batch.shape}\")\n        \n        batch_size = inputs_batch.shape[0]  # Get the actual size of the current batch\n        \n        # Ensure the current index is within bounds\n        start = i * generator.batch_size\n        end = start + batch_size\n        \n        # Prevent exceeding the number of samples\n        end = min(end, num_samples)\n        \n        if start >= num_samples: \n            break\n        \n        features[start:end] = features_batch[:end-start]\n        labels[start:end] = np.argmax(labels_batch[:end-start], axis=1)\n        \n        i += 1\n        \n        # Break the loop when enough samples have been processed\n        if end >= num_samples:\n            break\n\n    return features, labels\nnum_train_samples = train_generator.samples\nnum_test_samples = test_generator.samples\n\ntrain_features, train_labels = extract_features(train_generator,intermediate_layer_model, num_train_samples)\ntest_features, test_labels = extract_features(test_generator,intermediate_layer_model, num_test_samples)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.savez('inception_features_labels_final.npz', \n         train_features=train_features, train_labels=train_labels,\n         test_features=test_features, test_labels=test_labels)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"svm_model = SVC(C=1.0, kernel='rbf', gamma='scale',  probability=True)\n\n# Train the model using grid search\nsvm_model.fit(train_features, train_labels)\n\n# Make predictions on validation data\ntest_predictions = svm_model.predict(test_features)\n\nprint(classification_report(test_labels, test_predictions, target_names=class_labels.values()))\n\naccuracy = accuracy_score(test_labels, test_predictions)\nprecision = precision_score(test_labels, test_predictions, average='weighted')\nrecall = recall_score(test_labels, test_predictions, average='weighted')\nf1 = f1_score(test_labels, test_predictions, average='weighted')\n\n\nprint(f\"Overall Accuracy: {accuracy:.4f}\")\nprint(f\"Precision (Weighted): {precision:.4f}\")\nprint(f\"Recall (Weighted): {recall:.4f}\")\nprint(f\"F1-Score (Weighted): {f1:.4f}\")\n\n\ncm = confusion_matrix(test_labels, test_predictions)\nplt.figure(figsize=(10, 7))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels.values(), yticklabels=class_labels.values())\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}